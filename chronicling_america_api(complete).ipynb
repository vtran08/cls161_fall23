{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg1_EIHEETuB"
   },
   "source": [
    "# Chronicling America API\n",
    "\n",
    "[Chronicling America](https://chroniclingamerica.loc.gov/) is a collection of digitized American newspapers dating from 1777 to 1963 provided by the Library of Congress. The collection offers an application programming interface (API) which allows users to easily harvest large amounts of data.\n",
    "\n",
    "In this notebook we will search Chronicling America's API, gather the search results into a Pandas dataframe, clean the data, and save it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q0-jsD68ELup"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uoseSCpoEghd"
   },
   "outputs": [],
   "source": [
    "# initial search\n",
    "url = 'https://chroniclingamerica.loc.gov/search/pages/results/?state=&date1=1770&date2=1865&proxtext=\"time+travel\"&x=20&y=8&dateFilterType=yearRange&rows=20&searchType=basic&format=json'\n",
    "response = requests.get(url)\n",
    "raw = response.text\n",
    "results = json.loads(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-IV4qxIKlXW"
   },
   "source": [
    "## Explore search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pg-9a2pIKTnO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['totalItems', 'endIndex', 'startIndex', 'itemsPerPage', 'items'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jB1fHVUTEcLl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# explore items\n",
    "print(type(results['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LduCA0d1Etzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 1, 'county': ['Terrebonne'], 'edition': None, 'frequency': 'Weekly', 'id': '/lccn/sn83026391/1856-09-06/ed-1/seq-1/', 'subject': ['Houma (La.)--Newspapers.', 'Louisiana--Houma.--fast--(OCoLC)fst01218915'], 'city': ['Houma'], 'date': '18560906', 'title': 'Houma Ceres. [volume]', 'end_year': 1899, 'note': ['Archived issues are available in digital format as part of the Library of Congress Chronicling America online collection.', 'Democrat.', 'With legal notices in English and French.'], 'state': ['Louisiana'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Houma, Parish of Terrebonne, La.', 'start_year': 1855, 'edition_label': '', 'publisher': 'E.W. Blake & Co.', 'language': ['English'], 'alt_title': [], 'lccn': 'sn83026391', 'country': 'Louisiana', 'ocr_eng': 'INDEPENDENT IN ALL TING8-N.UTRAL IN NONM\\ni. . AN5E.MO.J DEVOTED TO LITERATURE, THE ARTS, AND NEWS OF THE DAY. 1[S per Anrum.\\nOL. II. HO[UMA, PARISH OF TERREBONNE, LA., SATURDAY, SEPTEMBER 6, 1856. NO. 10.\\ny..aeU3TS will be inased tbs waae do ne\\nten (o li es or less,) hrh tenr, and\\ný aulasquent imesnis A libeal\\name to tsea who adr1bsW by the ear.\\na yw wth be hargedhr hlff a noims\\nJialide dwertislag and Sats of graqter\\nbe admitte nalny fame.\\n,uga&W IO g--etauetiam d s. a\\nt orsIsthaas\\'aedeeasdtohe of pg&\\nuasyemeae nadanrta (at the op\\nedi betel is aidvaace.\\n8crawtllbecbar\\nO j 1dlne fur aln to be padd\\nýO~i o~3, net e1C5diflg thaseeor four fam,\\nbu tpsle d withote eha use, i1 theae\\n*N bffe raed as advrtlsaents.\\naweIeffiarsed that as aatica what\\nat any so l ation inteded for\\nmpsers areamsatuaad by the name and address\\n\" die ueeshtt ·aa l sr )rOrrlr, bt e a\\naaal hr jas lhM istssas.\\n1. wbT?~O~rS di t .aatimli~ L theiir mb\\ni Uth ideb\\' whswint of otce nsewt\\nqS sey eaesno ii\"\\'4 M la m adnn them nir auh\\n~·\\'L abiihae~t Sdbi~q.~ sme of thei nwsr\\nc~~an~S ad titanuntil aS\\nZ~l Ahfir~bl isqsst take their mew.\\nppsapemathse dea m awhich they~ mr directed, theyy\\nwer tea ab rthem aadil they hare \"adaded their bib\\na then cdelnU ed.\\n4. The Cumri. hare addad that I rL lt ofate news.\\nptperbin Uthe 1Wce~ety 6 anuavisagal. ew an\\ncmiolbr, bf w*5rd\"N·- iutaea5i5sl fraud,\\n3. Tie U(hiti.ed hi5Osibass l In rpatol dedi\\nd that apuedserwo erise tow thes\\naelfee. as yheýstC) Deprntment, of the\\niraaaglatear i eaia to.8elram the she\\nap to him ra.4,aa tlbs PemZebsasta e\\n1 l ibsi5IIdRdULkb5R\\nTeezu fing b ,s\\n\\'tat\\nto PFj-wiow~wlý,\\n5.. 84\\n\\'\" i~\\'\\'· \"t Tifrii1: `fit: rl\\n411 Al1\\nrlclf ~ m~tsm !\\'t?)IO~P~~If~:L·. gti ii\\n- I- ,4\\n,yIrI\\n-S \\'\\nNkad\\n-fr\\'··~\\nRhe Llits u Iasea. Asure J m\\nThe Baton Rouge Advocate gives the\\nannexed account of a visit to the Insane I\\nAsylum of Jackson :\\nWe took advantage of a visit to the\\ncommencement of Centenary College to\\ngo through this noble institution, a fitting\\nmonument to State philanthropy and gen- i\\nerosity. Dr. Mayberry, the Superinten.\\ndent and resident physician, we found at\\nhis post, as eager to extend the hospitali.\\nties of the asylum to visitors as he has\\never been found ready to administer to the\\nnecessities of the unfortunate beings con.\\nsigned to his care by this most protecting I\\nand humane commonwealth. Dr. M. is[\\nyet at the head of the asylum, though we\\nregret to say, has signified his intention of\\nresigning the post for which his skill as a\\nphysician and sympathy for nature\\'s afflict. I\\ned childret so eminently qualify him.\\nlie is prompted to this in consequence o\\nthe duties being too arduous and exacting\\nfor his constitution, besides the insufi\\nciency of the salary. We are told by\\nseveral that the pittance allowed by the\\nState to this ofljfer will not justify any\\nphysician of merit in abandoning his prac\\ntice and assumingt its responsibilities and\\nlabenrs. :\\nDr. M. accompanied us through the\\nhbilitings and freely communicated what.\\never intelligence of its mahagement and\\ncondion d we mught. The afeeping\\nap\\'tientib`are well ventihated, the-sanded\\n-obs °kepti Melean, and the linen on the\\nbeds wduld lialletgi the admiration of w\\nstpint/ fbgr its wh.t.; ess. There are\\nnow alibt 1$ 0i eiths\\' in the asylum, half\\nof whom are-m Jem Of this whole\\nemaipderý ýar nation.\\naie,\\' lncudtngz eseven negroes. the\\nrisb d eW \\'- taces -predoetinate\\nliagslyi) eostitatiag perhaps - halfm of\\nthe whole umber. in.s.m f the ijonstes\\nkem ePhlo a ni d arewisel s lr aerated\\nch=s\\'sb ros fros\\n,be nI~teed by re . r\\nebtae aq some\\nchamismd. u ouse`in front\\n4 oht g\\' r\\n\\' t: &ba\\'re\\n.x iz \\'444\\nr\\n`\"- 1rrr\\nA PICTCaE or DISUNION.- I I hps fare\\nwell address to his countrymen upon re.\\ntiring from the presidency, the patriot\\nstatesman and hero of the Hermitage\\nsaid :\\n\" What have you to gain by division and\\ndissension f Delude not yourselves with\\nthe hope that the breach, once made,\\nwould be afterwards easily repaired. If\\nthe Union is, once severed, the separation\\nwill grow wider and wider; and the con\\ntroversies which are now debated and\\nsettled in the halls of legislation will be\\ntried in the field of battle and determined\\nby the sword. Neither should you deceive\\nyourselves with the hope that the first line\\nofseparation would be the permanent one\\nS * * * Local interests would I\\nstill be found there, and unchastened am.\\nbition. And if the recollection ofcommon\\ndangers, in which the people of these\\nUnited States have stood side by side\\nagainst the common fte-the memory of\\nvictories won by their united valor-the\\nprosperity and, happiness they have en\\njoyed under theo present constitution-if\\nall these recollections and profs of com.\\nmoo interest are not strong 4nough to\\nbind us together as one people, what tie\\nwill hold united the new divisions of em-.\\npire When these bonds have been broken\\nand this Union dissolved F The first line\\nof separation would not last long; taew\\nfragments woald be torn off, new leaders\\nwould spring up, and this great and glo.\\nrieus republic would soon be broken into\\na multitude of petty States, armed for mu\\ntual aggression--loaded with taxes to pay\\narmies andu leaders-seeking and against\\neach other fomn foreignn powems-insulted\\nand trampled upon by the nations of\\nEurope-until, harrassed with conticts\\nand hImbled and debased in spirit, they\\nwould be willing to submit to the domi.\\nnio, of any military adventurer, and t\\nsurrender their liberty for the sake o\\nimeooae.\"\\n.T UC\"Cn you stmrat ha.b tsi dollslI\\nthis moauing te purchase a new bonnet.\\nmy\\' deatr. said a -lady one morning at\\nbreiakfiast.\\n\"By and by, love.\\'?\\nS\"\\'hat\\'- what you always say, mnydear,\\nbat.how eaa I hs.,ad i. y witheut mes.\\nAam thatbrongbl the money, just as ens\\nsod4aurndeserves another. Her wit was\\na..auesem that ssh tried it again the\\naWst wmekl\\nI: L:wan tweantdollass, mydear,4olhy\\naew dioes.sr New . Years.\"\\nýWuliyou satabt have it; Jw waled\\ntae.d\\'t a dsi1\" p hber huosbAnd.\\n,:walklea4 ads knadw that waeon.\\nly heausiyes aree -m food of hugging.\"\\nit hitai b just right again, and shegot\\n,the noms end something extra,as he let\\nhis p. e v.: soad hlrridda~ ato business.\\n,\"-itstee ar &ibGs: o eepaach a wife\\n,as yeu a e t i * oth it\"L\\n-i&rr k·aato d o ns 07 Rit\\nuregaoudl ait ty, our\\nht ehiad three of\\n\\'aye Aee; ~c &iea Aurioma, \"NiI\\naA I. to a ow - ev ijuer\\nj ~i ibir~amsg8otsaof\\noaro ~is~ i auof`spr sr. -b.\\nBetminherI.t uasy or aki\\n1 ýdii akirbhueo o of . Duuiisg\\nwith =thiireetoofýPrussia \" in\\na S t a. e i fs-* sas -lost in\\ntw.4ia twecItSaisepthw.\\nr =- 4w r fh abs IJiestaumba.f Blk.\\nA Miganiu. leisbee s Reid\\n--ot1 f b lam. tou\\nNipmtds alms Curios~Jo-ir~l\\na LM eon;-i\\' , use\\n{tom, #hi ;giupiaºdeepotic\\n`s~5&a and is is\\nSeleý ad ya\\nflrrJ\\nSi·;riy;:~h-~Pl3; 1iriiar\\n···- -·\\'- rj.l~ wigE- at.L~\\n1~~-5 .-,~. we.\\'2 ~*\\naepd; I\\'i-iiehmL\\nisa\\'\\nd: `&i·roi\"irl\"d of~~\\'C~id\\n~3jiNt~~dlpaf3,s~ ,,~\\nbsqmI ricem. frequently destro.y .\\nvirtu oetbeir owhssnor.\\nRailroad, Expremes, &c.\\nNEW ORLEANS, OPELOUSAS &\\nG. W. R. R.\\nUMMER AiRRANGEMENTS.-\\nS PAsssxwoa TaatSa:\\nLeave the Depot at Algiers every day at........ 780 A. a.\\nGretna every day at ........... .7:40 A. _\\nArrive at Bayo\" Boeul every day at .......... 11:30A. .\\ntziTuautame.\\nLeave Bayou Boeof ...........................1t15h . Y.\\nArrive at Gretna.............................4 r. .\\nat olgiers ...........................4 .i . n.\\nExcurskoa tikets to gotn the regular statrions ad bade\\nthe sme day will be ismoed as follows:\\nTo Botte, $1 25; to Bayou des Allemands, 1t 58; to\\nlreeland, I urche Oresln. and Terrebonne. ~S 0. to\\nTigerville, $3: to Bayou Boeaf, $300. Between inter\\nmediate regular stations prices proportional.\\nA Ferry Boat wil connect with the Passager Tmrain\\nleaving the foot or St. Ann street every morning, at 7 o clock\\nprecisely.\\ndrieght will be received Gfr B. Boeuf and intermediate\\nStations by the Company on the wharf at the toot of St\\nLouis astreet every day until 3 o\\'clock P. , All p u rieght\\nmast be paid by the shippers. and frleeht to be delivered at\\nall other Stations than Bayou des Allemanos, Raceland.\\nLafourche Crossing, Terreboome, Tigerrilie and Bayou\\nBoeud. (wherethe Company has Agents) most be prepaid.\\nPrinted Bales and Rates of rieght npeamphiet frms for\\ncirculation, to be had on applicatica at the ofee of the\\nmpeaany.. A. B. BSGER, iee Premadeds\\nHO! FOR THE RAILROAD!\\nJOu1 BD.RGR bae pNlt.he 5lage\\nend preax upon the inue liom\\nIonma o thse alanned cteiing, Terra\\nbonn. Dpot capable of ctfyg twelve pn .\\nThe Expre will leave Hnouna every meenlnag at eght\\ndo\\'ck, ,mad retauing . Hemt, Will m v he bDepot\\namoealately on the arrival of the car flto the City,\\nsay at half past II.\\nPARE EACH WAY, - - - -01\\nIe bope, by attendleg 47 wants adt coavealace of\\nthe traveling public to merit o share of theirpetrot e.\\nHe has costantiy on hand cstaveyasee of klad at\\nHowPs ain coevey pamue s. In any dirction.\\nHotel and istable.\\nThe undersigned would also informn his\\nfriends nap the publie that he is pregaed to accmmo\\ndite al who may call upon him. with coosfortabn Iltrg\\nIs, and his stable I alwagy well supp!ad with the best\\nthatea hbe procured In in the narket- Every exertion\\nwill bemle.so adm wster to comlbrt and omvencease d\\nbiasue. :\\nHis stables are well stocked, and maas of conveyance\\nmay bepeome.tat all time. Travel. conveyed to any\\nperst u thuc .ty. at a ltmeas, and on the most . smoo\\nDec Or JOHN BllRGR\\nHEOOMA EXPIR$S8.\\n. HOLDEs hasom nowd*ced upo.\\npets ar l ewe, s . vf ttrfi·\\nend retaurn to IHsm. wil Igi the Btqau\\n\\'1w Iheuutnd adt Jseaiae *\\nlire eea Q W ....U.........................$1 `s\\n3.i B,.-AU \"eeteam emepmet pu pa sI the lsrb\\npue repre. St t~~UhegT·eltwe S¶ hS\\ntto Ab agu0 m rit h Kw a\\neeid-naeds- o eepsetber pdliek.\\nOpterer the eky, pe Empra wI he mrtwe.!d at N\\nmer er nsvediits pols ed hwarded with de pliel\\nei WAYe the pim .be patp pet P\\n¶.ist onl y the etmno s eyutemo of .\"tqeI s 1.-=\\ninikees \\' atr~e eedU st -W\\nji\\'ap,~ehgemdmt betedd\\np ýrnt 3.1.AlUmQ,!e LDUW .\\n,iy I K . - B l HOU 15\\nSTABLLNG!\\nNEW STABLE is *@ about comu\\np1s lt., .in4I .p psnim. to omg oa lb. Uwya\\nb.*emIn nf lb Wamcbs. vebicis. The ay\\n.Iaeaykbd auies d.Nbilr y at S u$nsoSS.\\n5`°\" jlrach b ~ ad di o em bwo~ncr reo\\nMP.~wbS*a* fiuwghftd and mb am meu4 ..\\n.x, 1.* - oall;\\n~il~oL~.·ls ~ i-mi\\'-,kJ~.\\nSUBMBOIUER ha op band sbat\\nat $700 r s* en Q e Is W46 to am . tifii p po\\nopi.bmdusd t1ler~w~efr\\n- q,ý theyd\\'lkt183 uI\\n,~~)~;;YLs~k\"j4 ~ I~~~I\\nRa · tRils r SSA, 1853. reM\\nw iLnt3 oraawof AP 003 BILL,\\nw.ku1t wm*i W\\ntby.asy. brw\\nIethetap i withaif~ · itw\\nt 10 Yai4hper t ws.wilt tbibm ,ý.s..\\n:.\\'r i. - T r *. Y j\\nertaeua m t i Is\\nIl~h)~lt Boa~l~aF\\'It \\'C~\\nJg4IIee4SmeqC I msapawIs\\naise. S ses. aa fsaWtb3l s\\'\\ndo tits :..* wnlc` s#.\\nso.c\\ntealsP\\' -wllr qwt\\nthrl a s ees 1U S *s nliit\\n\\'7.lawsra~s .. IY4larf ý\\ný\" #w. wkr. J\\n_--:·-·f;; `~ · IW 1º C\\n11t w :r· . ·.\\nS MHDICINES.- f.-A au.\\nJiu1s1 1-0 w Di:r. ?Ieyus\\' usrN-N w g a+.\\n... Iiwme. flhZEI.1 nn DocaS.\\ntledicltes, &c.\\nFRIZELL & BROOKS,\\nDEALEBRS IN\\nDRUGS & MEDWI ECIES,\\nHoxIA, LA.\\n\" Physiea\\' Prueesrlptions carefully dirpene.d.\\nAlso-English and French Perfumery, German rologse,\\nSnap., Pomades. Oils Tonics for the Hair, Tooth, N.ll and\\nHair Brushes, Combs,eleantTTiletand Fancy Artoles,&\\nPure Wines and Brandies,\\nlar Medicinal Purposes, Choice Cigars, Painlat Oils, YVr\\nni.hes, Window GOas, Putty. Dye Stuh, Alcohols ..r\\npentine, Congress and Ble Lick Waer.\\nBOOKS, 1TAT.IONEKY, kc -el.\\nAYhf\\'S PILLS,\\neure ol-U Bi~oadea-- Catvenfr m nd\\nseae Jaundice, Dropsy, Rheumatism, Feers,\\n, luor:, Nervousness, Irritabity, Inama.\\natin4 Pain in the Brerast, Side, Back\\nand jrsb ale Complaints, &nc. &o. Indeu\\nvery few are tiseases in which a Prgative Mdi\\neins is not more or less required. no much sick\\nnes and satArlg might be prevente. if a harm\\nhoe blatteetngl Cathartic were more irev ed.\\nNo peron can feel well while a cosure nait of\\nbody ,ad;. beside, it soon genuac es anoa a\\nofteni ftsl dhesase, w lch might have been avoided\\ntihef isljdiikou rise of agood purgatýhe\\ni Col Feverr syptom.and\\nh loaudh l hIS bdrv a lL an\\nableo iý,yiu is of the suet >lo~ertance\\nthe public her and this Pill has been perfoted\\nwith eonsmmae sill tomeet that deo. h h.\\nextensive trial of its virtues by Physicians, Profwq\\nmr, ad Patipntp, has shown results surpssg\\nany thing hiherto kunea of say medisial Cags\\nhave been effected beyond belie wre they not sb\\nsatetiated y pions of -adi exated position sad\\n\". h IFa cf the. s Par , we *ey Mentiou\\nProf J. I. Locu, Analytical Chit, of U1r\\nwnaiwhea high professional chaseter i A\\n4 Hoe. J..Y Iiao G.e.rOfr...\\nWo sde ot., eo o the Wt st\\nleen u ae, buts e ttvi5 csavlnslaj\\nfltoe o of sl.e\\ns-edt . ttheretes\\nN yostld e fr handedbsik\\n\"pey wet rehan ada se\\nl wto s be taken tr lal s com s. . .\\nesir. a i tvat roe t -fam\\ni Awen such a 1wnuecaaonu\\n*lw ** * tsil\\nI eirrabet t A . . sdlrso a fl4ie IIe\\nsrativ vwatnen. a .,i th _rtius * k\\nl.ead Cestth fet ahound Provlle s thoy h\\npvemore ont veeae than aaditheto beeno\\ni . ettp.diin tipmym..i.ada ]\\nhedi±a e taskr.ent t \\'I.eIe at,. 1\\nefiatis capaens. Auotitg ipatsad eaeotIest\\nore alte atent es aaye>dreainued. heas Y;,\\nbe woldhetaken if their e o ws\\nT i ls F e In *PUL a\" ie 4\\nOPf ll the Patent Med e rn - thwa\\nD sL AME 0. AYE17,\\nWall . l S wh re c i tt t# rms\\ns, Fdum the fLO9K ra at the afofhne fu\\nA.~ ypm~uraL- rr·~ce U. 3.,\\nttinrr4· LI ifs a stin t )PrC s.\\nrU~. P. fo\\nIL MWnr I t\\nLJ.A . A. X4lDA,.J.A.\\ng 3Ncm vw. 3Lo.0G ShOE, Timt.\\nx~J3.Pk3L1 -~ WsIq J viz. us\\n·I r:', 'batch': 'lu_gonne_ver01', 'title_normal': 'houma ceres.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn83026391/1856-09-06/ed-1/seq-1.json', 'place': ['Louisiana--Terrebonne--Houma'], 'page': ''}\n"
     ]
    }
   ],
   "source": [
    "print(results['items'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kIcPNqHuKtJA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalItems: 10506\n",
      "endIndex: 20\n",
      "startIndex: 1\n",
      "itemsPerPage: 20\n",
      "Length and type of items: 20 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('totalItems:', results['totalItems'])\n",
    "print('endIndex:', results['endIndex'])\n",
    "print('startIndex:', results['startIndex'])\n",
    "print('itemsPerPage:', results['itemsPerPage'])\n",
    "print('Length and type of items:', len(results['items']), type(results['items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OmJIDL1lKy0g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n"
     ]
    }
   ],
   "source": [
    "# find total amount of pages\n",
    "total_pages = math.ceil(results['totalItems'] / results['itemsPerPage'])\n",
    "print(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "C0pZe96qBP_J"
   },
   "outputs": [],
   "source": [
    "# create empty list for data\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pg63qYBuBVU3"
   },
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "start_date = '1770'\n",
    "end_date = '1865'\n",
    "search_term = 'time+travel'\n",
    "state = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Upp6d0I9UDy6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 status code: 200\n",
      "page 2 status code: 200\n",
      "page 3 status code: 200\n",
      "page 4 status code: 200\n",
      "page 5 status code: 200\n",
      "page 6 status code: 200\n",
      "page 7 status code: 200\n",
      "page 8 status code: 200\n",
      "page 9 status code: 200\n",
      "page 10 status code: 200\n",
      "page 11 status code: 200\n",
      "page 12 status code: 200\n",
      "page 13 status code: 200\n",
      "page 14 status code: 200\n",
      "page 15 status code: 200\n",
      "page 16 status code: 200\n",
      "page 17 status code: 200\n",
      "page 18 status code: 200\n",
      "page 19 status code: 200\n",
      "page 20 status code: 200\n",
      "page 21 status code: 200\n",
      "page 22 status code: 200\n",
      "page 23 status code: 200\n",
      "page 24 status code: 200\n",
      "page 25 status code: 200\n",
      "page 26 status code: 200\n",
      "page 27 status code: 200\n",
      "page 28 status code: 200\n",
      "page 29 status code: 200\n",
      "page 30 status code: 200\n",
      "page 31 status code: 200\n",
      "page 32 status code: 200\n",
      "page 33 status code: 200\n",
      "page 34 status code: 200\n",
      "page 35 status code: 200\n",
      "page 36 status code: 200\n",
      "page 37 status code: 200\n",
      "page 38 status code: 200\n",
      "page 39 status code: 200\n",
      "page 40 status code: 200\n",
      "page 41 status code: 200\n",
      "page 42 status code: 200\n",
      "page 43 status code: 200\n",
      "page 44 status code: 200\n",
      "page 45 status code: 200\n",
      "page 46 status code: 200\n",
      "page 47 status code: 200\n",
      "page 48 status code: 200\n",
      "page 49 status code: 200\n",
      "page 50 status code: 200\n",
      "page 51 status code: 200\n",
      "page 52 status code: 200\n",
      "page 53 status code: 200\n",
      "page 54 status code: 200\n",
      "page 55 status code: 200\n",
      "page 56 status code: 200\n",
      "page 57 status code: 200\n",
      "page 58 status code: 200\n",
      "page 59 status code: 200\n",
      "page 60 status code: 200\n",
      "page 61 status code: 200\n",
      "page 62 status code: 200\n",
      "page 63 status code: 200\n",
      "page 64 status code: 200\n",
      "page 65 status code: 200\n",
      "page 66 status code: 200\n",
      "page 67 status code: 200\n",
      "page 68 status code: 200\n",
      "page 69 status code: 200\n",
      "page 70 status code: 200\n",
      "page 71 status code: 200\n",
      "page 72 status code: 200\n",
      "page 73 status code: 200\n",
      "page 74 status code: 200\n",
      "page 75 status code: 200\n",
      "page 76 status code: 200\n",
      "page 77 status code: 200\n",
      "page 78 status code: 200\n",
      "page 79 status code: 200\n",
      "page 80 status code: 200\n",
      "page 81 status code: 200\n",
      "page 82 status code: 200\n",
      "page 83 status code: 200\n",
      "page 84 status code: 200\n",
      "page 85 status code: 200\n",
      "page 86 status code: 200\n",
      "page 87 status code: 200\n",
      "page 88 status code: 200\n",
      "page 89 status code: 200\n",
      "page 90 status code: 200\n",
      "page 91 status code: 200\n",
      "page 92 status code: 200\n",
      "page 93 status code: 200\n",
      "page 94 status code: 200\n",
      "page 95 status code: 200\n",
      "page 96 status code: 200\n",
      "page 97 status code: 200\n",
      "page 98 status code: 200\n",
      "page 99 status code: 200\n",
      "page 100 status code: 200\n",
      "page 101 status code: 200\n",
      "page 102 status code: 200\n",
      "page 103 status code: 200\n",
      "page 104 status code: 200\n",
      "page 105 status code: 200\n",
      "page 106 status code: 200\n",
      "page 107 status code: 200\n",
      "page 108 status code: 200\n",
      "page 109 status code: 200\n",
      "page 110 status code: 200\n",
      "page 111 status code: 200\n",
      "page 112 status code: 200\n",
      "page 113 status code: 200\n",
      "page 114 status code: 200\n",
      "page 115 status code: 200\n",
      "page 116 status code: 200\n",
      "page 117 status code: 200\n",
      "page 118 status code: 200\n",
      "page 119 status code: 200\n",
      "page 120 status code: 200\n",
      "page 121 status code: 200\n",
      "page 122 status code: 200\n",
      "page 123 status code: 200\n",
      "page 124 status code: 200\n",
      "page 125 status code: 200\n",
      "page 126 status code: 200\n",
      "page 127 status code: 200\n",
      "page 128 status code: 200\n",
      "page 129 status code: 200\n",
      "page 130 status code: 200\n",
      "page 131 status code: 200\n",
      "page 132 status code: 200\n",
      "page 133 status code: 200\n",
      "page 134 status code: 200\n",
      "page 135 status code: 200\n",
      "page 136 status code: 200\n",
      "page 137 status code: 200\n",
      "page 138 status code: 200\n",
      "page 139 status code: 200\n",
      "page 140 status code: 200\n",
      "page 141 status code: 200\n",
      "page 142 status code: 200\n",
      "page 143 status code: 200\n",
      "page 144 status code: 200\n",
      "page 145 status code: 200\n",
      "page 146 status code: 200\n",
      "page 147 status code: 200\n",
      "page 148 status code: 200\n",
      "page 149 status code: 200\n",
      "page 150 status code: 200\n",
      "page 151 status code: 200\n",
      "page 152 status code: 200\n",
      "page 153 status code: 200\n",
      "page 154 status code: 200\n",
      "page 155 status code: 200\n",
      "page 156 status code: 200\n",
      "page 157 status code: 200\n",
      "page 158 status code: 200\n",
      "page 159 status code: 200\n",
      "page 160 status code: 200\n",
      "page 161 status code: 200\n",
      "page 162 status code: 200\n",
      "page 163 status code: 200\n",
      "page 164 status code: 200\n",
      "page 165 status code: 200\n",
      "page 166 status code: 200\n",
      "page 167 status code: 200\n",
      "page 168 status code: 200\n",
      "page 169 status code: 200\n",
      "page 170 status code: 200\n",
      "page 171 status code: 200\n",
      "page 172 status code: 200\n",
      "page 173 status code: 200\n",
      "page 174 status code: 200\n",
      "page 175 status code: 200\n",
      "page 176 status code: 200\n",
      "page 177 status code: 200\n",
      "page 178 status code: 200\n",
      "page 179 status code: 200\n",
      "page 180 status code: 200\n",
      "page 181 status code: 200\n",
      "page 182 status code: 200\n",
      "page 183 status code: 200\n",
      "page 184 status code: 200\n",
      "page 185 status code: 200\n",
      "page 186 status code: 200\n",
      "page 187 status code: 200\n",
      "page 188 status code: 200\n",
      "page 189 status code: 200\n",
      "page 190 status code: 200\n",
      "page 191 status code: 200\n",
      "page 192 status code: 200\n",
      "page 193 status code: 200\n",
      "page 194 status code: 200\n",
      "page 195 status code: 200\n",
      "page 196 status code: 200\n",
      "page 197 status code: 200\n",
      "page 198 status code: 200\n",
      "page 199 status code: 200\n",
      "page 200 status code: 200\n",
      "page 201 status code: 200\n",
      "page 202 status code: 200\n",
      "page 203 status code: 200\n",
      "page 204 status code: 200\n",
      "page 205 status code: 200\n",
      "page 206 status code: 200\n",
      "page 207 status code: 200\n",
      "page 208 status code: 200\n",
      "page 209 status code: 200\n",
      "page 210 status code: 200\n",
      "page 211 status code: 200\n",
      "page 212 status code: 200\n",
      "page 213 status code: 200\n",
      "page 214 status code: 200\n",
      "page 215 status code: 200\n",
      "page 216 status code: 200\n",
      "page 217 status code: 200\n",
      "page 218 status code: 200\n",
      "page 219 status code: 200\n",
      "page 220 status code: 200\n",
      "page 221 status code: 200\n",
      "page 222 status code: 200\n",
      "page 223 status code: 200\n",
      "page 224 status code: 200\n",
      "page 225 status code: 200\n",
      "page 226 status code: 200\n",
      "page 227 status code: 200\n",
      "page 228 status code: 200\n",
      "page 229 status code: 200\n",
      "page 230 status code: 200\n",
      "page 231 status code: 200\n",
      "page 232 status code: 200\n",
      "page 233 status code: 200\n",
      "page 234 status code: 200\n",
      "page 235 status code: 200\n",
      "page 236 status code: 200\n",
      "page 237 status code: 200\n",
      "page 238 status code: 200\n",
      "page 239 status code: 200\n",
      "page 240 status code: 200\n",
      "page 241 status code: 200\n",
      "page 242 status code: 200\n",
      "page 243 status code: 200\n",
      "page 244 status code: 200\n",
      "page 245 status code: 200\n",
      "page 246 status code: 200\n",
      "page 247 status code: 200\n",
      "page 248 status code: 200\n",
      "page 249 status code: 200\n",
      "page 250 status code: 200\n",
      "page 251 status code: 200\n",
      "page 252 status code: 200\n",
      "page 253 status code: 200\n",
      "page 254 status code: 200\n",
      "page 255 status code: 200\n",
      "page 256 status code: 200\n",
      "page 257 status code: 200\n",
      "page 258 status code: 200\n",
      "page 259 status code: 200\n",
      "page 260 status code: 200\n",
      "page 261 status code: 200\n",
      "page 262 status code: 200\n",
      "page 263 status code: 200\n",
      "page 264 status code: 200\n",
      "page 265 status code: 200\n",
      "page 266 status code: 200\n",
      "page 267 status code: 200\n",
      "page 268 status code: 200\n",
      "page 269 status code: 200\n",
      "page 270 status code: 200\n",
      "page 271 status code: 200\n",
      "page 272 status code: 200\n",
      "page 273 status code: 200\n",
      "page 274 status code: 200\n",
      "page 275 status code: 200\n",
      "page 276 status code: 200\n",
      "page 277 status code: 200\n",
      "page 278 status code: 200\n",
      "page 279 status code: 200\n",
      "page 280 status code: 200\n",
      "page 281 status code: 200\n",
      "page 282 status code: 200\n",
      "page 283 status code: 200\n",
      "page 284 status code: 200\n",
      "page 285 status code: 200\n",
      "page 286 status code: 200\n",
      "page 287 status code: 200\n",
      "page 288 status code: 200\n",
      "page 289 status code: 200\n",
      "page 290 status code: 200\n",
      "page 291 status code: 200\n",
      "page 292 status code: 200\n",
      "page 293 status code: 200\n",
      "page 294 status code: 200\n",
      "page 295 status code: 200\n",
      "page 296 status code: 200\n",
      "page 297 status code: 200\n",
      "page 298 status code: 200\n",
      "page 299 status code: 200\n",
      "page 300 status code: 200\n",
      "page 301 status code: 200\n",
      "page 302 status code: 200\n",
      "page 303 status code: 200\n",
      "page 304 status code: 200\n",
      "page 305 status code: 200\n",
      "page 306 status code: 200\n",
      "page 307 status code: 200\n",
      "page 308 status code: 200\n",
      "page 309 status code: 200\n",
      "page 310 status code: 200\n",
      "page 311 status code: 200\n",
      "page 312 status code: 200\n",
      "page 313 status code: 200\n",
      "page 314 status code: 200\n",
      "page 315 status code: 200\n",
      "page 316 status code: 200\n",
      "page 317 status code: 200\n",
      "page 318 status code: 200\n",
      "page 319 status code: 200\n",
      "page 320 status code: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 321 status code: 200\n",
      "page 322 status code: 200\n",
      "page 323 status code: 200\n",
      "page 324 status code: 200\n",
      "page 325 status code: 200\n",
      "page 326 status code: 200\n",
      "page 327 status code: 200\n",
      "page 328 status code: 200\n",
      "page 329 status code: 200\n",
      "page 330 status code: 200\n",
      "page 331 status code: 200\n",
      "page 332 status code: 200\n",
      "page 333 status code: 200\n",
      "page 334 status code: 200\n",
      "page 335 status code: 200\n",
      "page 336 status code: 200\n",
      "page 337 status code: 200\n",
      "page 338 status code: 200\n",
      "page 339 status code: 200\n",
      "page 340 status code: 200\n",
      "page 341 status code: 200\n",
      "page 342 status code: 200\n",
      "page 343 status code: 200\n",
      "page 344 status code: 200\n",
      "page 345 status code: 200\n",
      "page 346 status code: 200\n",
      "page 347 status code: 200\n",
      "page 348 status code: 200\n",
      "page 349 status code: 200\n",
      "page 350 status code: 200\n",
      "page 351 status code: 200\n",
      "page 352 status code: 504\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m raw \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m status code:\u001b[39m\u001b[38;5;124m'\u001b[39m, response\u001b[38;5;241m.\u001b[39mstatus_code)  \u001b[38;5;66;03m# checking for errors\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(raw)\n\u001b[0;32m     10\u001b[0m items_ \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item_ \u001b[38;5;129;01min\u001b[39;00m items_:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# loop through search results and collect data\n",
    "for i in range(1, total_pages+1):  # for sake of time I'm doing only 10, you will want to put total_pages+1\n",
    "    url = (f'https://chroniclingamerica.loc.gov/search/pages/results/?state={state}&date1={start_date}'\n",
    "           f'&date2={end_date}&proxtext={search_term}&x=16&y=8&dateFilterType=yearRange&rows=20'\n",
    "           f'&searchType=basic&format=json&page={i}')  # f-string\n",
    "    response = requests.get(url)\n",
    "    raw = response.text\n",
    "    print(f'page {i} status code:', response.status_code)  # checking for errors\n",
    "    results = json.loads(raw)\n",
    "    items_ = results['items']\n",
    "    for item_ in items_:\n",
    "        row_data = {}\n",
    "        try:\n",
    "          row_data['title'] = item_['title_normal']\n",
    "        except:\n",
    "          row_data['city'] = \"none\"\n",
    "        try:\n",
    "          row_data['city'] = item_['city']\n",
    "        except:\n",
    "          row_data['city'] = \"none\"\n",
    "        try:\n",
    "          row_data['date'] = item_['date']\n",
    "        except:\n",
    "          row_data['date'] = \"none\"\n",
    "        try:\n",
    "          row_data['raw_text'] = item_['ocr_eng']\n",
    "        except:\n",
    "          row_data['raw_text'] = 'none'\n",
    "    data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "q-ctFdtSBa-u"
   },
   "outputs": [],
   "source": [
    "# put data into DataFrame\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "prL29Su_msjb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delaware journal.</td>\n",
       "      <td>[Wilmington]</td>\n",
       "      <td>18280311</td>\n",
       "      <td>s\\nT\\nK\\nTl\\n4\\nA\\n4\\njg\\n'ËâUe&amp;lrç JÆ. BTadïo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sioux city register.</td>\n",
       "      <td>[Sioux City]</td>\n",
       "      <td>18640227</td>\n",
       "      <td>Sioirt Citir Register\\nSATURDAY, FEBRUARY 27, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vermont watchman and state journal.</td>\n",
       "      <td>[Montpelier]</td>\n",
       "      <td>18500704</td>\n",
       "      <td>VERMONT WATCHMAN STAE JOURNAL, sJULY 4, 1850.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tarboro' press.</td>\n",
       "      <td>[Tarboro]</td>\n",
       "      <td>18510315</td>\n",
       "      <td>-4\\ni\\nV. 5 279.\\nTarborough, Edgecombe County...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st. mary's beacon.</td>\n",
       "      <td>[Leonardtown]</td>\n",
       "      <td>18530512</td>\n",
       "      <td>PREPARATION OF SEED CORN. I\\nCorn-planting sc&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title           city      date  \\\n",
       "0                    delaware journal.   [Wilmington]  18280311   \n",
       "1                 sioux city register.   [Sioux City]  18640227   \n",
       "2  vermont watchman and state journal.   [Montpelier]  18500704   \n",
       "3                      tarboro' press.      [Tarboro]  18510315   \n",
       "4                   st. mary's beacon.  [Leonardtown]  18530512   \n",
       "\n",
       "                                            raw_text  \n",
       "0  s\\nT\\nK\\nTl\\n4\\nA\\n4\\njg\\n'ËâUe&lrç JÆ. BTadïo...  \n",
       "1  Sioirt Citir Register\\nSATURDAY, FEBRUARY 27, ...  \n",
       "2  VERMONT WATCHMAN STAE JOURNAL, sJULY 4, 1850.\\...  \n",
       "3  -4\\ni\\nV. 5 279.\\nTarborough, Edgecombe County...  \n",
       "4  PREPARATION OF SEED CORN. I\\nCorn-planting sc&...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z509dIQEep7G"
   },
   "source": [
    "### Change date format\n",
    "Pandas allows us to clean and edit our data easily (relatively). We can first convert the string values in the date column to properly formated dates and then sort the dataframe by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "z1fENcFaZJIx"
   },
   "outputs": [],
   "source": [
    "# convert date column from string to date-time object\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4c0otcZIey1D"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delaware journal.</td>\n",
       "      <td>[Wilmington]</td>\n",
       "      <td>1828-03-11</td>\n",
       "      <td>s\\nT\\nK\\nTl\\n4\\nA\\n4\\njg\\n'ËâUe&amp;lrç JÆ. BTadïo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sioux city register.</td>\n",
       "      <td>[Sioux City]</td>\n",
       "      <td>1864-02-27</td>\n",
       "      <td>Sioirt Citir Register\\nSATURDAY, FEBRUARY 27, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vermont watchman and state journal.</td>\n",
       "      <td>[Montpelier]</td>\n",
       "      <td>1850-07-04</td>\n",
       "      <td>VERMONT WATCHMAN STAE JOURNAL, sJULY 4, 1850.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tarboro' press.</td>\n",
       "      <td>[Tarboro]</td>\n",
       "      <td>1851-03-15</td>\n",
       "      <td>-4\\ni\\nV. 5 279.\\nTarborough, Edgecombe County...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st. mary's beacon.</td>\n",
       "      <td>[Leonardtown]</td>\n",
       "      <td>1853-05-12</td>\n",
       "      <td>PREPARATION OF SEED CORN. I\\nCorn-planting sc&amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title           city       date  \\\n",
       "0                    delaware journal.   [Wilmington] 1828-03-11   \n",
       "1                 sioux city register.   [Sioux City] 1864-02-27   \n",
       "2  vermont watchman and state journal.   [Montpelier] 1850-07-04   \n",
       "3                      tarboro' press.      [Tarboro] 1851-03-15   \n",
       "4                   st. mary's beacon.  [Leonardtown] 1853-05-12   \n",
       "\n",
       "                                            raw_text  \n",
       "0  s\\nT\\nK\\nTl\\n4\\nA\\n4\\njg\\n'ËâUe&lrç JÆ. BTadïo...  \n",
       "1  Sioirt Citir Register\\nSATURDAY, FEBRUARY 27, ...  \n",
       "2  VERMONT WATCHMAN STAE JOURNAL, sJULY 4, 1850.\\...  \n",
       "3  -4\\ni\\nV. 5 279.\\nTarborough, Edgecombe County...  \n",
       "4  PREPARATION OF SEED CORN. I\\nCorn-planting sc&...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wjTfqq38e0XB"
   },
   "outputs": [],
   "source": [
    "# sort by date\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3XYFLmRhe7Gp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>gazette of the united states, &amp; philadelphia d...</td>\n",
       "      <td>[Philadelphia]</td>\n",
       "      <td>1799-06-29</td>\n",
       "      <td>TREASURY DEPARTMENT.\\nMarch tlth, &lt;799.\\nPUBLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>enquirer.</td>\n",
       "      <td>[Richmond]</td>\n",
       "      <td>1810-08-21</td>\n",
       "      <td>ignorant that it is requisite to have permis\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>alexandria daily gazette, commercial &amp; political.</td>\n",
       "      <td>[Alexandria]</td>\n",
       "      <td>1812-02-13</td>\n",
       "      <td>I Instead of agreeing to it, postpon\\nscn'‘t'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>alexandria gazette, commercial and political.</td>\n",
       "      <td>[Alexandria]</td>\n",
       "      <td>1815-01-28</td>\n",
       "      <td>. ..._ •---_______;___^&gt; ■ -»■\\n'coThse salt.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>elizabeth-town gazette.</td>\n",
       "      <td>[Elizabeth]</td>\n",
       "      <td>1818-09-15</td>\n",
       "      <td>POETRY\\nFrom the Wilmington JVatehman.\\nSATURD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title            city  \\\n",
       "200  gazette of the united states, & philadelphia d...  [Philadelphia]   \n",
       "55                                           enquirer.      [Richmond]   \n",
       "33   alexandria daily gazette, commercial & political.    [Alexandria]   \n",
       "50       alexandria gazette, commercial and political.    [Alexandria]   \n",
       "259                            elizabeth-town gazette.     [Elizabeth]   \n",
       "\n",
       "          date                                           raw_text  \n",
       "200 1799-06-29  TREASURY DEPARTMENT.\\nMarch tlth, <799.\\nPUBLI...  \n",
       "55  1810-08-21  ignorant that it is requisite to have permis\\n...  \n",
       "33  1812-02-13  I Instead of agreeing to it, postpon\\nscn'‘t'l...  \n",
       "50  1815-01-28  . ..._ •---_______;___^> ■ -»■\\n'coThse salt.\\...  \n",
       "259 1818-09-15  POETRY\\nFrom the Wilmington JVatehman.\\nSATURD...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epH12SFJfJm6"
   },
   "source": [
    "### Process text\n",
    "We can now porcess our text for analysis. The text provded by Chronicling America comes from optical character recognition (ocr) and the accuracy of ocr can be low. Here I will remove new line characters (`\\n`), stop words, and then lemamtize the text.\n",
    "\n",
    "**Rememeber** the decisions you make in how to process your text should be based on the kind of analysis you want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "m6Urrlffe8ro"
   },
   "outputs": [],
   "source": [
    "# write fuction to process text\n",
    "# load nlp model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.disable_pipes('ner', 'parser')  # these are unnecessary for the task at hand\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"Remove new line characters and lemmatize text. Returns string of lemmas\"\"\"\n",
    "    text = text.replace('\\n', ' ')\n",
    "    doc = nlp(text)\n",
    "    tokens = [token for token in doc]\n",
    "    no_stops = [token for token in tokens if not token.is_stop]\n",
    "    no_punct = [token for token in no_stops if token.is_alpha]\n",
    "    lemmas = [token.lemma_ for token in no_punct]\n",
    "    lemmas_lower = [lemma.lower() for lemma in lemmas]\n",
    "    lemmas_string = ' '.join(lemmas_lower)\n",
    "    return lemmas_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VkQk9wuXfrwM"
   },
   "outputs": [],
   "source": [
    "# apply process_text function\n",
    "# this may take a few minutes\n",
    "df['lemmas'] = df['raw_text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7UU3K6rkfsRM"
   },
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(f'C:/Users/vivia/Downloads/cls161/cls161_fall23/{search_term}{start_date}-{end_date}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
